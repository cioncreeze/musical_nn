{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import mitdeeplearning as mdl \n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm \n",
    "import my_helpers as mh\n",
    "import mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "songs [ 60 129 129 ... 129  72 129]\n"
     ]
    }
   ],
   "source": [
    "#assert len(tf.config.list_physical_devices('GPU')) > 0\n",
    "mid = mido.MidiFile('./inputs/inp_1_cMaj_4-4th_temp_1.mid')\n",
    "song1 = mh.extract_bars('./inputs/inp_1_cMaj_4-4th_temp_1.mid')\n",
    "song2 = mh.extract_bars('./inputs/inp_2_cMaj_4-4th_temp_1.mid')\n",
    "song3 = mh.extract_bars('./inputs/inp_3_cMaj_4-4th_temp_1.mid')\n",
    "song4 = mh.extract_bars('./inputs/inp_4_cMaj_4-4th_temp_1.mid')\n",
    "song5 = mh.extract_bars('./inputs/inp_5_cMaj_4-4th_temp_1.mid')\n",
    "\n",
    "songs = np.array(song1 + song2 + song3 + song4 + song5).flatten()\n",
    "\n",
    "print(\"songs\", songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 5 batch_size 1\n",
      "x_batch [[129  69 129  72 129]] y_batch [[ 69 129  72 129  69]]\n"
     ]
    }
   ],
   "source": [
    "def get_batch(song_list, seq_length, batch_size):\n",
    "    # get length of inputs and randomly take subset\n",
    "    n = song_list.shape[0] - 1\n",
    "    idx = np.random.choice(n-seq_length, batch_size)\n",
    "    # create matching subsets of input and output strings for rnn\n",
    "    input_batch =  [song_list[i : i+seq_length] for i in idx]\n",
    "    output_batch = [song_list[i+1 : i+seq_length+1] for i in idx]\n",
    "    #create batches in proper size to feed to rnn\n",
    "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "    y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "    print(\"seq_len\", seq_length, \"batch_size\", batch_size)\n",
    "    print(\"x_batch\", x_batch, \"y_batch\", y_batch)\n",
    "    return x_batch, y_batch\n",
    "\n",
    "x_batch, y_batch = get_batch(songs, 5, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard lstm stolen from the internet\n",
    "def LSTM(rnn_units): \n",
    "    return tf.keras.layers.LSTM(\n",
    "        rnn_units, \n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        recurrent_activation='sigmoid',\n",
    "        stateful=True,)\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    # vocab size is the number of possible values the inputs (and outputs) can take on\n",
    "    # i. e. the number of unique characters (or numbers) in the data set \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        LSTM(rnn_units),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "#model = build_model(vocab_size, embedding_dim=256, rnn_units=1024, batch_size=32)\n",
    "\n",
    "# custom loss functions\n",
    "\n",
    "def compute_loss(labels, logits):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "\n",
    "num_training_iterations = 20\n",
    "batch_size = 32\n",
    "seq_length = 100\n",
    "learning_rate = 5e-3\n",
    "\n",
    "vocab_size = 130 # number of unique characters in dataset\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "checkpoint_dir = './rnn_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# custom training step \n",
    "def train_step(x, y): \n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = model(x) \n",
    "        loss = compute_loss(y, y_hat) \n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables) \n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "history = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 60 129  59 ... 129  67 129]\n",
      " [129  76 129 ... 129 129  67]\n",
      " [129  76 129 ...  72 129 129]\n",
      " ...\n",
      " [ 64 129  65 ... 129  69 129]\n",
      " [129 129  81 ... 129  81 129]\n",
      " [ 76 129  79 ... 129  76 129]] y_batch [[129  59 129 ...  67 129  69]\n",
      " [ 76 129  74 ... 129  67 129]\n",
      " [ 76 129 129 ... 129 129 129]\n",
      " ...\n",
      " [129  65 129 ...  69 129  67]\n",
      " [129  81 129 ...  81 129  79]\n",
      " [129  79 129 ...  76 129  72]]\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(songs, seq_length=100, batch_size=32)\n",
    "pred = model(x)\n",
    "#print(\"pred0[]\", pred[0], pred[0].shape)\n",
    "\n",
    "predicted_id = tf.random.categorical(pred[0], num_samples=1)[-1,0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129 129  77 ... 129  77 129]\n",
      " [ 60 129  62 ... 129  65 129]\n",
      " [129  72 129 ...  79 129  76]\n",
      " ...\n",
      " [129 129  77 ... 129  69 129]\n",
      " [129  81 129 ...  86 129  84]\n",
      " [129  72 129 ...  65 129  62]] y_batch [[129  77 129 ...  77 129 129]\n",
      " [129  62 129 ...  65 129  64]\n",
      " [ 72 129  76 ... 129  76 129]\n",
      " ...\n",
      " [129  77 129 ...  69 129  71]\n",
      " [ 81 129  79 ... 129  84 129]\n",
      " [ 72 129  71 ... 129  62 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:05<01:45,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 72 129  69 ... 129  74 129]\n",
      " [ 60 129 129 ... 129  67 129]\n",
      " [ 62 129 129 ... 129 129 129]\n",
      " ...\n",
      " [129  62 129 ...  67 129  67]\n",
      " [ 79 129  76 ... 129  72 129]\n",
      " [ 74 129  72 ... 129  72 129]] y_batch [[129  69 129 ...  74 129  72]\n",
      " [129 129 129 ...  67 129  69]\n",
      " [129 129 129 ... 129 129  67]\n",
      " ...\n",
      " [ 62 129  65 ... 129  67 129]\n",
      " [129  76 129 ...  72 129  67]\n",
      " [129  72 129 ...  72 129  74]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:10<01:38,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  72 129 ... 129 129  60]\n",
      " [129  67 129 ...  58 129  62]\n",
      " [ 72 129 129 ... 129  76 129]\n",
      " ...\n",
      " [ 79 129 129 ... 129 129 129]\n",
      " [ 69 129  67 ... 129  74 129]\n",
      " [ 76 129  74 ... 129  72 129]] y_batch [[ 72 129  71 ... 129  60 129]\n",
      " [ 67 129  60 ... 129  62 129]\n",
      " [129 129 129 ...  76 129  74]\n",
      " ...\n",
      " [129 129 129 ... 129 129  81]\n",
      " [129  67 129 ...  74 129  71]\n",
      " [129  74 129 ...  72 129 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:16<01:32,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 67 129  69 ... 129  76 129]\n",
      " [ 72 129  74 ... 129  74 129]\n",
      " [129  65 129 ...  71 129  72]\n",
      " ...\n",
      " [ 72 129  67 ... 129  60 129]\n",
      " [129  64 129 ...  74 129  76]\n",
      " [ 76 129  74 ... 129 129 129]] y_batch [[129  69 129 ...  76 129  72]\n",
      " [129  74 129 ...  74 129 129]\n",
      " [ 65 129  67 ... 129  72 129]\n",
      " ...\n",
      " [129  67 129 ...  60 129  57]\n",
      " [ 64 129  65 ... 129  76 129]\n",
      " [129  74 129 ... 129 129  62]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:21<01:26,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129 129  77 ... 129  76 129]\n",
      " [129  72 129 ...  72 129  77]\n",
      " [ 64 129  65 ... 129  65 129]\n",
      " ...\n",
      " [129 129 129 ...  67 129  69]\n",
      " [129  67 129 ...  74 129  71]\n",
      " [129 129  76 ... 129 129 129]] y_batch [[129  77 129 ...  76 129  77]\n",
      " [ 72 129  76 ... 129  77 129]\n",
      " [129  65 129 ...  65 129  64]\n",
      " ...\n",
      " [129 129  69 ... 129  69 129]\n",
      " [ 67 129  65 ... 129  71 129]\n",
      " [129  76 129 ... 129 129  72]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:26<01:20,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 72 129 129 ... 129  65 129]\n",
      " [129  76 129 ... 129 129  72]\n",
      " [129 129 129 ... 129 129  72]\n",
      " ...\n",
      " [ 65 129 129 ... 129  69 129]\n",
      " [129 129 129 ... 129 129  72]\n",
      " [129 129  69 ... 129  79 129]] y_batch [[129 129 129 ...  65 129  64]\n",
      " [ 76 129  74 ... 129  72 129]\n",
      " [129 129  79 ... 129  72 129]\n",
      " ...\n",
      " [129 129 129 ...  69 129  67]\n",
      " [129 129  64 ... 129  72 129]\n",
      " [129  69 129 ...  79 129  76]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:32<01:15,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  71 129 ...  72 129  74]\n",
      " [ 74 129  76 ... 129  76 129]\n",
      " [ 77 129  74 ... 129  76 129]\n",
      " ...\n",
      " [129  77 129 ...  84 129  86]\n",
      " [129  69 129 ...  74 129 129]\n",
      " [ 67 129  64 ... 129  62 129]] y_batch [[ 71 129  69 ... 129  74 129]\n",
      " [129  76 129 ...  76 129 129]\n",
      " [129  74 129 ...  76 129 129]\n",
      " ...\n",
      " [ 77 129  76 ... 129  86 129]\n",
      " [ 69 129  67 ... 129 129 129]\n",
      " [129  64 129 ...  62 129  64]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:37<01:09,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 64 129  69 ... 129  64 129]\n",
      " [129  81 129 ...  86 129  88]\n",
      " [129  79 129 ...  79 129  77]\n",
      " ...\n",
      " [129  71 129 ... 129 129  71]\n",
      " [ 64 129 129 ... 129  62 129]\n",
      " [129 129  60 ... 129  64 129]] y_batch [[129  69 129 ...  64 129  62]\n",
      " [ 81 129  79 ... 129  88 129]\n",
      " [ 79 129  77 ... 129  77 129]\n",
      " ...\n",
      " [ 71 129  72 ... 129  71 129]\n",
      " [129 129 129 ...  62 129  67]\n",
      " [129  60 129 ...  64 129 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:42<01:04,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  67 129 ...  77 129  79]\n",
      " [129  69 129 ...  79 129  76]\n",
      " [129  76 129 ...  74 129  76]\n",
      " ...\n",
      " [129 129  60 ... 129  65 129]\n",
      " [129  76 129 ...  76 129  79]\n",
      " [ 67 129  69 ... 129  64 129]] y_batch [[ 67 129  69 ... 129  79 129]\n",
      " [ 69 129  71 ... 129  76 129]\n",
      " [ 76 129  77 ... 129  76 129]\n",
      " ...\n",
      " [129  60 129 ...  65 129  69]\n",
      " [ 76 129  79 ... 129  79 129]\n",
      " [129  69 129 ...  64 129  62]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [00:48<00:58,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  76 129 ...  69 129  71]\n",
      " [ 60 129  59 ... 129  60 129]\n",
      " [ 71 129  69 ... 129 129 129]\n",
      " ...\n",
      " [129  62 129 ...  64 129  67]\n",
      " [ 74 129  72 ... 129  74 129]\n",
      " [129 129 129 ... 129 129  76]] y_batch [[ 76 129 129 ... 129  71 129]\n",
      " [129  59 129 ...  60 129  62]\n",
      " [129  69 129 ... 129 129  71]\n",
      " ...\n",
      " [ 62 129  60 ... 129  67 129]\n",
      " [129  72 129 ...  74 129  76]\n",
      " [129 129  76 ... 129  76 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [00:53<00:53,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 72 129  69 ... 129  74 129]\n",
      " [129  79 129 ...  64 129  60]\n",
      " [129  67 129 ...  65 129  62]\n",
      " ...\n",
      " [ 60 129 129 ... 129  55 129]\n",
      " [129  65 129 ... 129 129  60]\n",
      " [129 129  69 ... 129  71 129]] y_batch [[129  69 129 ...  74 129 129]\n",
      " [ 79 129  76 ... 129  60 129]\n",
      " [ 67 129  71 ... 129  62 129]\n",
      " ...\n",
      " [129 129 129 ...  55 129  60]\n",
      " [ 65 129  62 ... 129  60 129]\n",
      " [129  69 129 ...  71 129  74]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [00:59<00:48,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 69 129  72 ... 129  72 129]\n",
      " [ 74 129 129 ... 129 129 129]\n",
      " [129  62 129 ...  67 129 129]\n",
      " ...\n",
      " [129 129 129 ...  69 129  72]\n",
      " [129 129  69 ... 129  72 129]\n",
      " [129  74 129 ...  72 129  71]] y_batch [[129  72 129 ...  72 129 129]\n",
      " [129 129 129 ... 129 129  76]\n",
      " [ 62 129  59 ... 129 129 129]\n",
      " ...\n",
      " [129 129  67 ... 129  72 129]\n",
      " [129  69 129 ...  72 129  67]\n",
      " [ 74 129  72 ... 129  71 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [01:04<00:43,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 84 129  81 ... 129 129 129]\n",
      " [ 83 129  84 ... 129  81 129]\n",
      " [129 129 129 ...  74 129  77]\n",
      " ...\n",
      " [129  69 129 ...  74 129  72]\n",
      " [129  62 129 ...  64 129  65]\n",
      " [129  65 129 ...  77 129  79]] y_batch [[129  81 129 ... 129 129  72]\n",
      " [129  84 129 ...  81 129  79]\n",
      " [129 129  60 ... 129  77 129]\n",
      " ...\n",
      " [ 69 129  71 ... 129  72 129]\n",
      " [ 62 129  64 ... 129  65 129]\n",
      " [ 65 129  67 ... 129  79 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [01:09<00:37,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 62 129 129 ... 129 129 129]\n",
      " [ 59 129  60 ... 129  74 129]\n",
      " [129  59 129 ...  64 129  62]\n",
      " ...\n",
      " [ 72 129  71 ... 129  79 129]\n",
      " [ 62 129 129 ... 129  72 129]\n",
      " [ 69 129  72 ... 129  76 129]] y_batch [[129 129 129 ... 129 129  72]\n",
      " [129  60 129 ...  74 129  76]\n",
      " [ 59 129  60 ... 129  62 129]\n",
      " ...\n",
      " [129  71 129 ...  79 129  76]\n",
      " [129 129 129 ...  72 129  71]\n",
      " [129  72 129 ...  76 129  72]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [01:15<00:32,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  76 129 ...  69 129  71]\n",
      " [129  69 129 ...  59 129  60]\n",
      " [ 69 129  72 ... 129  79 129]\n",
      " ...\n",
      " [129 129  60 ... 129  77 129]\n",
      " [ 69 129  64 ... 129  76 129]\n",
      " [129 129  71 ... 129  77 129]] y_batch [[ 76 129  79 ... 129  71 129]\n",
      " [ 69 129  65 ... 129  60 129]\n",
      " [129  72 129 ...  79 129  76]\n",
      " ...\n",
      " [129  60 129 ...  77 129  74]\n",
      " [129  64 129 ...  76 129  76]\n",
      " [129  71 129 ...  77 129  74]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [01:20<00:26,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  72 129 ... 129 129  76]\n",
      " [ 69 129  67 ... 129  72 129]\n",
      " [ 62 129  64 ... 129 129 129]\n",
      " ...\n",
      " [ 76 129  74 ... 129  72 129]\n",
      " [ 72 129 129 ... 129 129 129]\n",
      " [129  72 129 ...  72 129  71]] y_batch [[ 72 129  81 ... 129  76 129]\n",
      " [129  67 129 ...  72 129  76]\n",
      " [129  64 129 ... 129 129  60]\n",
      " ...\n",
      " [129  74 129 ...  72 129  74]\n",
      " [129 129 129 ... 129 129  76]\n",
      " [ 72 129  69 ... 129  71 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [01:25<00:21,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  71 129 ...  65 129  67]\n",
      " [129  74 129 ...  69 129  72]\n",
      " [129  81 129 ...  79 129  77]\n",
      " ...\n",
      " [ 74 129  72 ... 129  72 129]\n",
      " [ 76 129  72 ... 129  74 129]\n",
      " [ 62 129 129 ... 129 129 129]] y_batch [[ 71 129  69 ... 129  67 129]\n",
      " [ 74 129  76 ... 129  72 129]\n",
      " [ 81 129  79 ... 129  77 129]\n",
      " ...\n",
      " [129  72 129 ...  72 129  71]\n",
      " [129  72 129 ...  74 129  76]\n",
      " [129 129 129 ... 129 129  67]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [01:31<00:15,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[ 74 129  67 ... 129  72 129]\n",
      " [129  79 129 ... 129 129  76]\n",
      " [ 69 129  69 ... 129  77 129]\n",
      " ...\n",
      " [129  65 129 ...  60 129 129]\n",
      " [129  79 129 ...  83 129  84]\n",
      " [129  76 129 ...  76 129  74]] y_batch [[129  67 129 ...  72 129  76]\n",
      " [ 79 129  74 ... 129  76 129]\n",
      " [129  69 129 ...  77 129  74]\n",
      " ...\n",
      " [ 65 129  67 ... 129 129 129]\n",
      " [ 79 129  81 ... 129  84 129]\n",
      " [ 76 129  72 ... 129  74 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [01:36<00:10,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  77 129 ...  77 129  76]\n",
      " [129  72 129 ...  81 129  83]\n",
      " [129 129 129 ... 129 129  72]\n",
      " ...\n",
      " [129 129 129 ...  72 129  74]\n",
      " [ 67 129  64 ... 129  60 129]\n",
      " [ 60 129 129 ... 129  48 129]] y_batch [[ 77 129  76 ... 129  76 129]\n",
      " [ 72 129 129 ... 129  83 129]\n",
      " [129 129  59 ... 129  72 129]\n",
      " ...\n",
      " [129 129  76 ... 129  74 129]\n",
      " [129  64 129 ...  60 129 129]\n",
      " [129 129 129 ...  48 129  55]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [01:41<00:05,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len 100 batch_size 32\n",
      "x_batch [[129  72 129 ...  77 129  76]\n",
      " [129  64 129 ...  71 129  72]\n",
      " [129 129  79 ... 129  67 129]\n",
      " ...\n",
      " [129  74 129 ...  57 129  62]\n",
      " [ 79 129  76 ... 129  64 129]\n",
      " [129  76 129 ...  81 129  79]] y_batch [[ 72 129  76 ... 129  76 129]\n",
      " [ 64 129  60 ... 129  72 129]\n",
      " [129  79 129 ...  67 129  69]\n",
      " ...\n",
      " [ 74 129  67 ... 129  62 129]\n",
      " [129  76 129 ...  64 129  72]\n",
      " [ 76 129  72 ... 129  79 129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:47<00:00,  5.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# run the network for a while\n",
    "for iter in tqdm(range(num_training_iterations)):\n",
    "    x_batch, y_batch = get_batch(songs, seq_length, batch_size)\n",
    "    #print(x_batch.shape, y_batch.shape)\n",
    "    loss = train_step(x_batch, y_batch)\n",
    "\n",
    "    history.append(loss.numpy().mean())\n",
    "\n",
    "    if iter % 100 == 0:     \n",
    "      model.save_weights(checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (1, None, 256)            33280     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (1, None, 130)            133250    \n",
      "=================================================================\n",
      "Total params: 5,413,506\n",
      "Trainable params: 5,413,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "gen_sng [ 64  75   2  48   1  21   6  42 106  46 101  96  71   4  35  25  75  41\n",
      "  48  91  69   6  26  96  57  53  77   6 111  56   7  35  89 109  47  29\n",
      "  75  91  58  61  90 100  26  60 115  46  78  50  14  35  67 116  69  95\n",
      "  33 100  24  25   5  15  63  34  10 127  57  94   8  33  68  77  87  18\n",
      "  95  65  62  31  87  73 102 126  63 108  39 112  72  87  24 124  89 105\n",
      "  26  40  28  60  62  52 107  61  12  19  37  65  27  91  12 118 115  27\n",
      "  14   7 104  33 105  71  75  12   9  34  91   7 121  39  10  96  17  11\n",
      "  30  81  37 102  59  42  70  64  52 128  40   2  54   6  33 111  51  71\n",
      "  77  54  37  22  94  63  42  99 119  90   9 113   3 127  50  52] (160,)\n"
     ]
    }
   ],
   "source": [
    "def generate_song(model, start_string, generation_length=100):\n",
    "    current_string = tf.expand_dims(start_string, 0)\n",
    "    #print(\"111111111\", current_string)\n",
    "    song_generated = []\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    #tqdm._instances.clear()\n",
    "    for i in range(generation_length):\n",
    "        predictions = model(current_string)\n",
    "        #print(\"p1\", predictions, predictions.shape)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        #print(\"p2\", predictions, predictions.shape)\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        #print(\"p3\", predicted_id)\n",
    "        current_string = tf.expand_dims([predicted_id],0)\n",
    "        song_generated.append(predicted_id)\n",
    "\n",
    "    return (np.array(start_string + song_generated).flatten())\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# Restore the model weights for the last checkpoint after training\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "generated_song = generate_song(model, start_string=[64], generation_length=159)\n",
    "print(\"gen_sng\", generated_song, generated_song.shape)\n",
    "generated_song = generated_song.reshape((16, -1))\n",
    "mh.write_to_file(generated_song.tolist(), mid.ticks_per_beat, filepath=\"./\", filename=\"rnn_recon\", stretch=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
